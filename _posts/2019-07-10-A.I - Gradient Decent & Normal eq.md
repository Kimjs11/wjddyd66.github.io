---
layout: post
title:  "A.I-Gradient Decent & Normal eq"
date:   2019-07-10 10:00:00 +0700
categories: [A.I]
---

### Gradient Decent & Normal eq
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<span style ="color: red">정규방정식(Normal equation 혹은 Ordinary least squares 혹은 linear least squares)은 통계학에서 선형 회귀상에서 알지 못하는 값(parameter)를 예측하기 위한 방법론이다. </span>  
<span style ="color: red">**경사 하강법이 수학적 최적화 알고리즘으로서 적절한 학습비율(learning rate)를 설정해야하고 많은 연산량이 필요**</span>하지만 정규방정식에는 그와 같은 단점이 없다는 장점이 있다. 하지만 정규방정식은 <span style ="color: red">**행렬 연산에 기반하기 때문에 피쳐의 개수가 엄청나게 많을 경우 연산이 느려지는 것**</span>을 피할 수 없다. 하지만 <span style ="color: red">**경사 하강법은 아무리 많은 피쳐가 존재하더라도 일정한 시간 내에 해법을 찾는 것이 가능**</span>하다. 그러므로 예측 알고리즘을 선택할 때 있어 <span style ="color: red">**피쳐의 개수**</span>에 따라 알맞은 것을 선택하여야 한다.  
### Normal eq
$$y= a X + b$$  
라는 식이 있을경우 이것을 행렬로서 표현할 수 있다.  
<p>$$\begin{bmatrix} Y \end{bmatrix} = \begin{bmatrix} X & 1 \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  
위의 식을 풀어서 쓰면 아래와 같이 나타낼 수 있다.  
<p>$$\begin{bmatrix} y_1\\y_2\\y_3\\...\\y_n \end{bmatrix} = \begin{bmatrix} x_1 & 1\\x_2 & 1\\x_3 & 1\\...\\x_n & 1 \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  

<p>$$\begin{bmatrix} X \\ Y \end{bmatrix} = \begin{bmatrix} \cos {(\alpha + \beta)} & -\sin {(\alpha + \beta)} \\ \sin {(\alpha + \beta)} & \cos {(\alpha + \beta)} \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix}$$</p>
<hr>
참조: <a href="https://www.youtube.com/watch?v=M9Gsi3VBTYM&list=PL1H8jIvbSo1q6PIzsWQeCLinUj_oPkLjc&index=22">Chanwoo Timothy Lee Youtube</a> <br>
참조: <a href="https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C%EB%B0%A9%EC%A0%95%EC%8B%9D">나무위키</a> <br>
문제가 있거나 궁금한 점이 있으면 wjddyd66@naver.com으로  Mail을 남겨주세요.