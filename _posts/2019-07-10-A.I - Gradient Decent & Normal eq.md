---
layout: post
title:  "A.I-Gradient Decent & Normal eq"
date:   2019-07-10 10:00:00 +0700
categories: [AI]
---

### Gradient Decent & Normal eq
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<span style ="color: red">**정규방정식(Normal equation 혹은 Ordinary least squares 혹은 linear least squares)은 통계학에서 선형 회귀상에서 알지 못하는 값(parameter)를 예측하기 위한 방법론이다.**</span>  
<span style ="color: red">**경사 하강법이 수학적 최적화 알고리즘으로서 적절한 학습비율(learning rate)를 설정해야하고 많은 연산량이 필요**</span>하지만 정규방정식에는 그와 같은 단점이 없다는 장점이 있다. 하지만 정규방정식은 <span style ="color: red">**행렬 연산에 기반하기 때문에 피쳐의 개수가 엄청나게 많을 경우 연산이 느려지는 것**</span>을 피할 수 없다. 하지만 <span style ="color: red">**경사 하강법은 아무리 많은 피쳐가 존재하더라도 일정한 시간 내에 해법을 찾는 것이 가능**</span>하다. 그러므로 예측 알고리즘을 선택할 때 있어 <span style ="color: red">**피쳐의 개수**</span>에 따라 알맞은 것을 선택하여야 한다.  
### Normal eq
$$y= a X + b$$  
라는 식이 있을경우 이것을 행렬로서 표현할 수 있다.  
<p>$$\begin{bmatrix} Y \end{bmatrix} = \begin{bmatrix} X & 1 \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  
위의 식을 풀어서 쓰면 아래와 같이 나타낼 수 있다.  
<p>$$\begin{bmatrix} y_1\\y_2\\y_3\\...\\y_n \end{bmatrix} = \begin{bmatrix} x_1 & 1\\x_2 & 1\\x_3 & 1\\...\\x_n & 1 \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  
Gradient Decent와 마찬가지로 우리가 구하고자 하는 것은 a,b의 값이다.  
만약 Normal eq의 식을 아래와 같이 만들 수 있으면 역행렬을 곱하여 a,b의 값을 구할 수 있을 것 이다.  
초기식  
<p>$$\begin{bmatrix} Y \end{bmatrix} = \begin{bmatrix} A \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  
역행렬을 곱하였을때  
<p>$$\begin{bmatrix} A \end{bmatrix}^{-1} \begin{bmatrix} Y \end{bmatrix} = \begin{bmatrix} A \end{bmatrix}^{-1} \begin{bmatrix} A \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  
최종적인 식  
<p>$$\begin{bmatrix} A \end{bmatrix}^{-1} \begin{bmatrix} Y \end{bmatrix} = C(상수)\begin{bmatrix} E \end{bmatrix}(기본행렬) \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  
<span style ="color: red">**이러한 a 와 b를 구하긴 위해서는 [X 1]의 행렬을 정방행렬(n x n크기의 행렬)로 바꿔야지 역행렬을 구할 수 있다.**</span>  

정방행렬 로 바꾸기 위하여 $$\begin{bmatrix} X \end{bmatrix}^{T} 행렬을 양변에 곱하게 되면  
<p>$$\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} y_1\\y_2\\y_3\\...\\y_n \end{bmatrix} = \begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} x_1 & 1\\x_2 & 1\\x_3 & 1\\...\\x_n & 1 \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix}$$</p>  

위의 식을 간단히 표현하면 아래 식과 같다.  

<p>$$\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} Y \end{bmatrix} = \begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix} \begin{bmatrix} A \end{bmatrix}$$</p>  

위의 식에서 행렬 A를 구하여 위하여 <span> \begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix} </span>의 역행렬을 곱하게 되면  
<p>$$(\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix})^{-1}\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} Y \end{bmatrix} = (\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix})^{-1}\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix} \begin{bmatrix} A \end{bmatrix}$$</p>  

<span>(\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix})^{-1}\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix}  = E(정방 행렬)</span>이므로 최종적인 식은 아래와 같다.

<p>$$(\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} X \end{bmatrix})^{-1}\begin{bmatrix} X \end{bmatrix}^{T}\begin{bmatrix} Y \end{bmatrix} = \begin{bmatrix} A \end{bmatrix}$$</p>  
<hr>
참조: <a href="https://www.youtube.com/watch?v=M9Gsi3VBTYM&list=PL1H8jIvbSo1q6PIzsWQeCLinUj_oPkLjc&index=22">Chanwoo Timothy Lee Youtube</a> <br>
참조: <a href="https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C%EB%B0%A9%EC%A0%95%EC%8B%9D">나무위키</a> <br>
문제가 있거나 궁금한 점이 있으면 wjddyd66@naver.com으로  Mail을 남겨주세요.