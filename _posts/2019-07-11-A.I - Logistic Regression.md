---
layout: post
title:  "A.I-Logistic Regression"
date:   2019-07-11 10:00:00 +0700
categories: [AI]
---

### Logistic Regression
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

로지스틱 회귀분석은 예측하는 Linear Regression과 달리 Y가 범주형일때 사용하게 된다.  
로지스틱 회귀는 이항형 또는 다향형이 될 수 있다. 종속변수의 결과가 2개의 종류라면 이항형, 그 이상이라면 다항형이다.  
이항형 다항형에 따라 활성화 함수(active function)이 아래와 같은 종류를 가지게 된다.  
<span style ="color: red">**이항형: 시그모이드 혹은 하이퍼 볼릭 탄젠트, 다항형: 소프트맥스**</span>
<a href="https://wjddyd66.github.io/r/2019/06/17/Regression.html">로지스틱 회귀분석 자세한 내용</a><br>

로지스틱 회귀분석에서 활성화 함수를 시그모이드를 사용한다고 하면 아래와 같은 식을 얻을 수 있다.  
<p> $$ y(x) = {1 \over 1+e^{-ax+b}}$$ </p><br>
위의 식에서 a값을 변화시켰을 경우 그래프의 기울기를 변화시킬 수 있고, b값을 변화시켜 그래프를 평행이동 시킬 수 있다.  
a값을 변화시켰을때의 시그모이드 그래프  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/5.png" height="250" width="600" /></div>
b값을 변화시켰을때의 시그모이드 그래프  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/6.png" height="250" width="600" /></div>

### Cross Entropy
Logistic Regression또한 Linear Regression과 같이 MSE를 사용하여 구할 수 있으나 Cross Entropy를 사용하여 Model의 성능을 향상시킬 수 있다.  
Cross Entropy를 이해하기 위해서 <span style ="color: red">**정보량, 엔트로피**</span>의 개념을 알고 있어야 한다.  
<br>
<span style ="color: red">**정보량**</span>은 아래와 같은 식으로 표현할 수 있다.  
<p>$$I(x) = log(\frac{1}{p(x)}) $$ </p><br>
<span>$$(1 \over p(x)) $$ </span>은 사건이 발생할 수 있는 확률이다.  
이러한 값에 log를 취함으로 인하여 <span style ="color: red">**필요한 최소한의 자원**</span>을 나타낸다.  
<br>
<span style ="color: red">**Entropy**</span>는 아래와 같은 식으로 표현할 수 있다.  
<p>$$H_p(X)=\sum_{i=0}^n  p(x_i)log(p(x_i)) $$ </p><br>
Entropy는 <span style ="color: red">**정보량에 대한 기댓값이며 동시에 사건을 표현하기 위해 요구되는 평균 자원이라고 할 수 있다.**</span>으로 정의된다.  
예측이 어려울수록 정보의 양은 더 많아지고 엔트로피는 더 커진다.  
<br>
<span style ="color: red">**Cross Entropy**</span>의식은 아래와 같다.  
<p>$$H_{p,q}(x)=\sum_{i=0}^n  p(x_i)log(q(x_i)) $$ </p><br>
Entropy는 <span style ="color: red">**p는 true label에 대한 분포를, q는 현재 예측모델의 추정값에 대한 분포**</span>를 의미하게 된다.  
위의 식은 아래와 같은 식으로 나타낼 수 있다.  
<p>$$f_c(x)=y\prime log(y) - (1-y\prime)log(1-y) $$ </p><br>
위의 식에서 우변의 값을 각각 따로 그래프로 그려보게 되면 아래와 같다.  
<span>$$y\prime log(y)$$ </span>그래프  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/7.png" height="250" width="600" /></div>
<span>$$(1-y\prime)log(1-y)$$ </span>그래프  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/8.png" height="250" width="600" /></div>
<span> $$ y(x) = {1 \over 1+e^{-ax+b}}$$ </span>식에서 a, b값을 조정함에 따라 위의 그래프들의 값이 아래 그림과 같이 변경된다.  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/9.PNG" height="250" width="600" /></div>
서로 값들이 상봔되는 관계를 가지고 있고 두개의 값을 더했을때 가장 작은 값을 찾는것을 목표로 한다.  

<hr>
참조: <a href="https://www.youtube.com/watch?v=kHLqMsN7yao&list=PL1H8jIvbSo1q6PIzsWQeCLinUj_oPkLjc&index=23">Chanwoo Timothy Lee Youtube</a> <br>
참조: <a href="https://curt-park.github.io/2018-09-19/loss-cross-entropy/">curt-park 블로그</a> <br>
문제가 있거나 궁금한 점이 있으면 wjddyd66@naver.com으로  Mail을 남겨주세요.