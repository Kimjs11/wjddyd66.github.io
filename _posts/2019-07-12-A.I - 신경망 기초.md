---
layout: post
title:  "A.I-신경망 기초"
date:   2019-07-12 10:00:00 +0700
categories: [AI]
---

### 신경망 기초
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

하나의 신경은 아래 그림과 같이 많이 표현한다.  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/13.PNG" height="250" width="600" /></div>
x1, x2, x2를 Input(입력)이라 한다.  
y는 Output(출력)이라고 한다.  
w1, w2, w2는 Weight(가중치)라고 한다.  
Activate Function은 들어오는 Input과 가중치를 활용하여 Output을 만들어내기 위한 식이다.  
위의 그림에서 Activate Function이 Sigmoid를 사용한다고 하면 아래와 같은 식을 얻어낼 수 있다.  
<p> $$ y(x) = {1 \over 1+e^{-(w_1x_1+w_2x_2+w_3x_3)}}$$ </p><br>
위의 그림과 같은 Node를 여러개를 연결하여 하나의 신경망을 구성하게 된다.  
신경망은 대부분 아래와 같이 표현할 수 있다.  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/14.PNG" height="250" width="600" /></div>
위와같은 그림은 아래와 같이 행렬로써 표현할 수 있다.  

Input Layer => Hidden Layer  
<p>$$\begin{bmatrix} w_00 & w_01 & w_02 \\w_10 & w_11 & w_12 \\w_20 & w_21 & w_22 \end{bmatrix} \begin{bmatrix} x_0 \\ x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} a\\b\\c \end{bmatrix} => sigmoid => \begin{bmatrix} h_0\\h_1\\h_2 \end{bmatrix}$$</p><br>

Hidden Layer => Output Layer
<p>$$\begin{bmatrix} w_00 & w_01 & w_02 \\w_10 & w_11 & w_12 \end{bmatrix} \begin{bmatrix} h_0 \\ h_1 \\ h_2 \end{bmatrix} = \begin{bmatrix} a\\b \end{bmatrix} => sigmoid => \begin{bmatrix} y_0\\y_1 \end{bmatrix}$$</p><br>

위의 식을 간단하게 표현한다면 아래와 같이 나타낼 수 있다.  
<p>$$H = g(W_1X)$$</p><br>
<p>$$Y = g(W_2H)$$</p><br>

<hr>
참조: <a href="https://www.youtube.com/watch?v=iJ6Kj4XZBzA&list=PL1H8jIvbSo1q6PIzsWQeCLinUj_oPkLjc&index=24">Chanwoo Timothy Lee Youtube</a> <br>
문제가 있거나 궁금한 점이 있으면 wjddyd66@naver.com으로  Mail을 남겨주세요.