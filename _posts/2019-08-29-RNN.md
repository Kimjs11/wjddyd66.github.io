---
layout: post
title:  "RNN"
date:   2019-08-29 12:00:00 +0700
categories: [Tensorflow]
---

### RNN
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
RNN(Recurrent Neural Network)이란 **순차적인 정보**를 처리하는 데 있다.  
즉, 이전 까지 반복하였던 **상관없는 두 변수간의 값으로 인한 정보를 처리하는 것이 아닌 한 정보에 대한 특정 Domain의 값을 나타내는 정보를 처리하는 것** 이다.  
예를 들어, 문장에서 다음에 나올 단어를 추측하고 싶다면 이전에 나온 단어들을 아는 것이 큰 도움이 될 것이다.  
또한 집의 가격이 어떻게 변할지에 대하여 한 집의 가격을 계속 관찰하게 되면 집의 가격이 **시간(Domain)에 따라 어떻게 변하는지 예측**할 수 있을 것이다.  
위의 예시가 가능한 이유는 동일한 Task에 대하여 **하나의 Hidden Layer**를 계속하여 Trainning 하기 떄문이다.  
출력 결과는 이전의 계산 결과에 영향을 받기 때문에 RNN은 현재지 계산된 결과에 대한 "메모리" 정보를 갖고 있다고 볼 수도 있다.  
RNN의 구조는 아래와 같이 나타낸다.  
<div><img  src="http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg" width="100%" height="100%"></div>
- <span>$$x_t$$</span>는 시간 스텝(time step) t 에서의 입력값이다.
- <span>$$x_t$$</span>는 시간 스텝(time step) t 에서의 Hidden state이다. 네트워크의 "메모리" 부분으로서, 이전 시간의 스텝의 hidden state 값과 현재 시간 스텝의 입력값에 의해 계산된다.  
<span>$$s_t = f(Ux_t + Ws_{t-1}) \text{   f는 tanh or ReLU}$$</span>
- <span>$$o_t$$</span>는 시간 스텝(time step)에서의 출력값이다. 예를 들어 다음 단어를 추축하고 싶다면 단어 수만큼의 차원의 확률 벡터가 될 것이다. <span>$$o_t = softmax(Vs_t)$$</span>

몇 가지 짚어두고 넘어갈 점이 있다.  
Hidden state s_t는 네트워크의 메모리라고 생각할 수 있다. s_t는 과거의 시간 스텝들에서 일어난 일들에 대한 정보를 전부 담고 있고, 출력값 o_t는 오로지 현재 시간 스텝 t의 메모리에만 의존한다. 하지만 위에서 잠깐 언급했듯이, 실제 구현에서는 너무 먼 과거에 일어난 일들은 잘 기억하지 못한다.  
각 layer마다의 파라미터 값들이 전부 다 다른 기존의 deep한 신경망 구조와 달리, RNN은 모든 시간 스텝에 대해 파라미터 값을 전부 공유하고 있다 (위 그림의 U, V, W). 이는 RNN이 각 스텝마다 입력값만 다를 뿐 거의 똑같은 계산을 하고 있다는 것을 보여준다. 이는 학습해야 하는 파라미터 수를 많이 줄여준다.  
위 다이어그램에서는 매 시간 스텝마다 출력값을 내지만, 문제에 따라 달라질 수도 있다. 예를 들어, 문장에서 긍정/부정적인 감정을 추측하고 싶다면 굳이 모든 단어 위치에 대해 추측값을 내지 않고 최종 추측값 하나만 내서 판단하는 것이 더 유용할 수도 있다. 마찬가지로, 입력값 역시 매 시간 스텝마다 꼭 다 필요한 것은 아니다. RNN에서의 핵심은 시퀀스 정보에 대해 어떠한 정보를 추출해 주는 hidden state이기 때문이다.  
출처: <a href="http://aikorea.org/blog/rnn-tutorial-1/">aikorea</a><br>



### RNN BackPropagation  
RNN을 아래와 같은 그림으로 같단히 나타내어 보자.  
<div><img src="http://www.wildml.com/wp-content/uploads/2015/10/rnn-bptt1.png" height="250" width="600" /></div><br>

위와 같은 그림에서 다음과 같은 식을 정의하고 가자  
Activation Function: tanh  
Classifier: Softmax  
<p>$$s_t = tanh(Ux_t + Ws_{t-1})$$</p>
<p>$$\hat{y_t} = softmax(Vs_t) $$</p>
<p>$$y_t \text{: 시간 스텝 t 에서 실제 단어, } \hat{y_t} text{: 예측값}$$</p>
Loss Function: Cross Entropy  
<p>$$E(y_t,\hat{y_t}) = -y_t log(\hat{y_t})$$</p>
<p>$$E(y,\hat{y}) = -\sum_t{E(y_t,\hat{y_t})}$$</p>
<p>$$= -\sum_t{-y_t log(\hat{y_t})}$$</p>

**Parameter U, V, W 에 대한 Error 의 Gradient 를 계산하고 SGD를 이용하여 Parameter를 최적화 하여 Loss를 적게 만드는 것이 목표이다.**  

**1. Parameter V**  
<p>$$\frac{\partial E_3}{\partial V} = \frac{\partial E_3}{\partial \hat{y_3}} \frac{\partial \hat{y_3}}{\partial V}$$</p>
<p>$$= \frac{\partial E_3}{\partial \hat{y_3}} \frac{\partial \hat{y_3}}{\partial z_3} \frac{\partial z_3}{\partial V} \text{       z_3 = Vs_3}$$</p>
<p>$$= (\hat{y_3} - y_3) \bigotimes s_3$$</p>

위의 식에서 <span>$$\frac{\partial E_3}{\partial \hat{y+3}} \frac{\partial \hat{y_3}}{\partial z_3}$$</span>의 경우 Softmax-with-Loss의 역전파로서 계산 과정을 건너 뛰었다.  
<a href="https://wjddyd66.github.io/tensorflow/2019/08/18/Logistic-Regression.html">Softmax-with-Loss의 역전파</a><br>

위의 식에서 주목해야 할 점은 **<span>$$\frac{\partial E_3}{\partial V}$$</span>은 현재 시간 스탭의 <span>$$\hat{y_3}, y_3, s_3$$</span>**에만 의존한다는 것이다.  
즉 **V Parameter를 갱신하는 것은 현재 시간 스탭의 값만 알아도 수행할 수 있다는 점** 이다.  

**2. Parameter W, U**  
위와 같은 CNN에서 ReLU와 Polling과정을 하나의 Hidden Layer라고 생각을 하면 다음과 같은 식을 얻을 수 있다.  
<p>$$\delta^{n} = W \delta^{n+1} \ast g\prime(x) $$</p>
하지만 Weigt를 곱해주는 것은 Convolution을 통하여 이루어지기 때문에 위의 식은 아래와 같이 표현할 수 있다.  
<p>$$\delta^{n} = W \ast \delta^{n+1} \circ g\prime(x)   (g(x): ReLu Function)$$</p>
<span style ="color: red">**CNN에서는 Pooling과정을 커치기 때문에 서로 Size가 달라서 SizeScaling 과정이 필요하게 된다.**</span>  
SizeScaling같은 경우 Kronecker Product를 통하여 이루어지게 된다.  
아래 과정은 **Kronecker Product**의 과정이다.  
<p>$$\begin{bmatrix} 1 & 2\\3 & 4 \end{bmatrix} x  \begin{bmatrix} 4 & 5\\6 & 7 \end{bmatrix} = \begin{bmatrix} 1x4 & 2x4 & 1x5 & 2x5 \\ 3x5 & 4x5 & 3x5 & 4x5 \\ 1x6 & 2x6 & 1x6 & 2x6 \\ 1x7 & 2x7 & 1x7 & 2x7  \end{bmatrix}$$</p>
이 된다.  
이러한 **Kronecker Product**을 CNN에서 사용할때 1의 원소를 가지고 있는 행렬로서 SizeScaling을 하게 되면 아래와 같은 식이 된다.  
<p>$$\begin{bmatrix} a & b\\c & d \end{bmatrix} x  \begin{bmatrix} 1 & 1\\1 & 1 \end{bmatrix} = \begin{bmatrix} a & a & a & a \\ b & b & b & b \\ c & c & c & c \\ d & d & d & d  \end{bmatrix}$$</p>
위의 **Kronecker Product** 과정을 up()으로 간단하게 표현하게 되고 다시 식으로서 나타내게 되면 아래와 같다.  
<p>$$\delta^{n} = W \ast \delta^{n+1} \circ up(g\prime(x))$$</p>

### CNN 구성
위의 개념인 Convolution을 활용하여 Neural Network를 어떻게 구성하는 지에 대해 알아보자.  

**(1) Kernel**  
Image(Input)에 Weigth를 곱하는 과정에서 Convolution이 일어나게 된다.  
CNN에서는 이러한 Weight를 **Kernel**이라고 한다.  
대표적으로 많이 사용되는 Kernel은 아래와 같다.  
<div><img src="https://t1.daumcdn.net/cfile/tistory/99EC29495C5D8ACF1C?download" height="500" width="600" /></div>
출처<a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">위키피디아</a><br>
Image(Input) 28 x 28 이 망을 통과하는 과정을 살펴보자.  
Kernel의 크기는 5 x 5라고 가정을 하게 되면  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/18.PNG" height="250" width="600" /></div>
위의 이미지처럼 28 x 28 Image에 5x5의 Kernel를 1칸씩 Sliding하면서 Fetch 의 범위안의 값들을 서로 곱한뒤 더해주는 과정이 일어나게 된다.  
이러한 과정을 **Convolution**이라고 불리게 된다.  
<span style ="color: red">**Kernel이 몇칸씩 이동하는 지는 사용자가 지정할 수 있고 이러한 이동하는 간격은 Stride라고 한다.**</span>  
Convolution연산은 아래와 같은 Tensorflow API로서 진행된다.  
**Convolution Tensorflow API**  
```python
tf.nn.conv2d( input, filter, strides, padding, dilations=[1,1,1,1], name=None )
```
- input: Input Data
- filter: Convolution 연산에 적용할 필터이며 [filter_height, filter_width, in_channels, out_channels] 형태의 4-D Tensor만 가능
- strides: 몇 Pixel 씩 넘어갈 지 지정
- padding
 - 'SAME': zero padding 을 통하여 input 과 같은 크기의 이미지가 return
 - 'VALID': Convolution 연산 공식에 의해 계산된 가로, 세로, 차원이 return
- dilation: Dilation Factor


<br><br>

**(2) Activation map**  
Convolution을 최종적으로 마친 값은 아래 그림과 같다.  
이러한 결과를 **Activation map**이라고 불리게 된다.  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/19.PNG" height="250" width="600" /></div>
28 x 28의 Image가 Convolution을 통해 최종적인 24 x 24의 Image로 축소하게 된다.  
<span style ="color: red">**이미지가 축소되는 것을 방지하기 위하여 이미지 둘레에 특정 값을 둘러쌀 수 가 있는데 이를 Padding이라고 불리게 된다.**</span>  
<br><br>
하나의 Weight가 아닌 모든 Weight를 적용하게 된다면 아래 그림과 같이 일어나게 된다.  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/20.PNG" height="250" width="600" /></div>
 - 원본 Image: 28 x 28  
 - Weiht: 5 x 5 x 5(Weight의 개수)
 - Sliding: 1칸씩
 - 처리 결과: 24(28-5+1) x 28 x 5(Weight개수)

<br><br>
**(3) ReLU**  
Feature Map에서 양의 값만을 활성화시키는 레이어이다.  
Feature Map에서 특히나 두드러지는 특징을 다시 추출하는 역할을 한다.  
Convolution의 특성을 위에서 이렇게 정의하였다.  
<span style ="color: red">**결과값이 클 수록 서로 같은 성분을 많이 가지고 있는것을 위의 그림에서 알 수 있다.**</span>  
즉, 큰 값일 수록 중요하기 때문에 5이상의 값에서 Gradinet값이 0으로 가까워지는 단점을 극복한 ReLU를 사용한다.  
<a href="https://wjddyd66.github.io/ai/2019/07/11/A.I-Active-Function.html">ReLU 사용이유</a>  

<br><br>
**(4) Pooling**  
위의 과정을 거친 다음 Pooling을 통해 값을 Reduce하는 과정이 일어난다.  

<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/21.PNG" height="250" width="600" /></div>
 - 처리결과: 24 x 24  
 - Pooling: 2 x 2
 - Sliding: 2칸씩
 - 처리 결과: 12(24/2) x 12

Pooling을 통해 24 x 24를 12 x 12인 반으로 Reduce하는 과정이 일어나게 된다.  
Pooling의 종류로는 최댓값을 뽑아내는 max pooling, 평균값을 뽑아내는 mean pooling등 다양한 종류가 존재한다.  
<span style ="color: red">**Pooling의 사용이유 크게 3가지로 나눌 수 있다.**</span>  
1. 정발 꼭 필요한 데이터만 뽑아낼 수 있다.
2. 데이터의 양이 작아진다.
3. Feature가 많아질 경우 Overfitting발생을 예방하기 위해서이다.

<br><br>
이러한 최종적인 과정을 그림으로서 표현하면 아래와 같다.  

<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/22.PNG" height="250" width="600" /></div>

Pooling연산은 아래와 같은 Tensorflow API로서 진행된다.  
**Pooling Tensorflow API**  
**Max Pooling**  
```python
tf.nn.max_pool( value, ksize, strides, name=None )
```
- value: Max Pooling을 적용시킬 Input Data
- ksize: Max Pooling 연산에 적용할 필터이며 [batch_filter,height_filter, width_filter, channel_filter]형태의 4-D Tensor만 가능
- strides: 몇 Pixel씩 넘어갈지 지정

**Mean Pooling**  
```python
tf.nn.avg_pool;( value, ksize, strides, name=None )
```
- value: Max Pooling을 적용시킬 Input Data
- ksize: Max Pooling 연산에 적용할 필터이며 [batch_filter,height_filter, width_filter, channel_filter]형태의 4-D Tensor만 가능
- strides: 몇 Pixel씩 넘어갈지 지정


**(5) Dropout**  
Dropout은 **Overfitting**을 막기위한 방법으로 뉴럴 네트워크가 학습중일때, 랜덤하게 뉴런을 꺼서 학습함으로써, 학습이 학습용 데이터로 치우치는 현상을 막아준다.  

<div><img src="https://t1.daumcdn.net/cfile/tistory/224A3941583ED6B109" height="250" width="600" /></div>
그림출처:<a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/dropout_layer.html">leonardoaraujosantos</a>  
일반적으로 CNN에서는 이 Dropout Layer를 **Fully connected Network(모든 Filter 와 Pooling 작업을  한 과정) 뒤에 놓지만, 상황에 따라서는 Pooling Layer뒤**에 놓기도 한다.  
아래 그림은 Dropout 적용과 적용하지 않은 Model사이의 예측 정확도를 비교한 결과이다.  

<div><img src="https://t1.daumcdn.net/cfile/tistory/262B4941583ED6B20C" height="250" width="600" /></div><br>

Dropout연산은 아래와 같은 Tensorflow API로서 진행된다.  
**Dropout Tensorflow API**  
```python
tf.nn.dropout( x, keep_prob, name=None )
```
- x: Dropout을 적용할 Input Data
- keep_prob: 드롭하지 않고 유지할 노드의 비율을 나타내는 scalar 텐서


<br><br>

**(6) Output(Softmax Function)**  
최종적인 결과를 확인하기 위해서 **Softmax Function으로서 Classification**을하게 된다.  
<a href="https://wjddyd66.github.io/ai/2019/07/11/A.I-Active-Function.html">Softmax자세한 내용</a><br>
최종적인 CNN의 그림은 아래와 같다.  

<div><img src="https://t1.daumcdn.net/cfile/tistory/23630641583ED6B01E" height="250" width="600" /></div><br>
그림출처:<a href="https://bcho.tistory.com/1149">bcho 블로그</a>

<br><br>  






<hr>
참조:<a href="https://github.com/wjddyd66/Tensorflow/blob/master/CNN.ipynb">원본코드</a><br>
참조: <a href="https://www.youtube.com/watch?v=4jgHzgxBnGY&list=PL1H8jIvbSo1q6PIzsWQeCLinUj_oPkLjc&index=15">Chanwoo Timothy Lee Youtube</a> <br>
참조: <a href="http://aikorea.org/blog/rnn-tutorial-1/">aikorea</a><br>
참조:텐서플로로 배우는 딥러닝<br>
문제가 있거나 궁금한 점이 있으면 wjddyd66@naver.com으로  Mail을 남겨주세요.