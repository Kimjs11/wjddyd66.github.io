---
layout: post
title:  "ROS(2)"
date:   2019-11-28 09:00:20 +0700
categories: [Others]
---

**LiDAR Institute 세미나에 대한 내용을 정리한 것 입니다.**  

현재 몇몇 사항은 사전측에서 미리 준비해둔 Setting으로 진행하므로 직접 구동하거나 실습하는데에는 무리가 있을 것으로 예상됩니다.  
실질적으로 오늘 실습에서 사용하는 Dataset의 경우 SOSLAB이 아닌 Velodyne LiDAR의 128 Channel의 Data이다.  
(여담으로 가격은 1억2천만원 정도이고 기기 자체가 없어서 Dataset을 구하는 것 자체가 어렵다고 한다.)  


### 실습 1 Complex-YOLOv3
(1) <code>roscore</code> 실행  

(2) <code>rviz -d ./catkin_ws/src/Complex-TOLOv3/KODAS_Labelcheck/rviz/kodas.rviz</code>: 실제 Daaset을 확인하기 위하여 지정한 rviz File을 RVIZ를 통하여 확인

(3) <code>./ros_demo_label.py --data_dir ./catkin_ws/src/Complex-ToLOv3/data/KODAS/sync_train</code>: 1Frame당 어떻게 Dataset이 구성되어있는지 확인하기 위하여 실행  
- Enter: Next Frame
- q: 종료

<br>
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/12.png" height="250" width="600" /></div><br>
(4) config _ kodas _ 2.py의 root_dir Direcotry를 COmplex-TOLOv3/KODAS/sync_train이 위치한 Directory로 바꾼다.

(5) Bird Top View를 확인한다.   
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/13.png" height="250" width="600" /></div><br>
(6) Model Training  
현재 Notebook 환경에서는 GPU Resource가 부족하여 돌려보지 못하였습니다.  
대신 현재 제공되어있는 Training되어 있는 logs와 Model을 통하여 결과를 확인하였습니다.  

(7) Tnesorboard로서 결과 확인  
<code>tensorboard --logdir=logs</code><br>
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/14.png" height="250" width="600" /></div><br>
(8) Model Test  
<code>/test_kodas.py --weights_path=checkpoints/yolov3_ckpt_epoch-22_MAP-0.50.pth</code><br>
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/15.png" height="250" width="600" /></div><br>
(8) Evaludation  
<code>$ ./eval_mAP.py --weights_path=checkpoints/yolov3_ckpt_epoch-22_MAP-0.50.pth</code><br>
마찬가지로 GPU의 Memory부족으로 인하여 실행 불가  

<br>

### 실습 2 SLAM
SLAM(Simultaneous Localization And Mapping)  
**Localization**: Map이 주여져 있을 때 특정 Object의 위치를 찾아내는 것  
**Mapping**: Localization이 주여져있을때 Map을 만들어가는 것  
즉, Map이 주어져 있지 않고 Map에서의 로봇의 위치도 알 수 없을 때 로봇이 주변 환경을 센서로 감지해가면서 Map을 만들고 그 Map에서의 자신의 위치까지 추정하는 작업이다.  

#### Visual SLAM
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/16.png" height="250" width="600" /></div><br>
(1) Workspace 생성 <code>mkdir -p slam_ws/src</code>  
(2) Source File Download <code>git clone https://github.com/appliedAI-Initiative/orb_slam_2_ros</code>  
(3) Launch File 수정 <code>vi ~/slam_ws/src/orb_slam_2_ros/ros/launch/orb_slam2_r200_mono.launch</code>  
Topic을 /camera/rgb/image_raw -> /camera/rgb/image_color
(4) Source 추가 <code>source ./devel/setup.bash</code>  
(5) orbslam2 _ ros Node 실행 <code>roslaunch orb_slam2_r200_mono.launch</code>  
(6) Rviz 실행 <code>rviz</code> -> Topic Map point topic, Image topic 추가  
(7) Bag File 실행 <code>rosbag play --clock rgbd_dataset_fireiburg3_teddy.bag -r 0.5</code>

**참고사항**  
현재 Notebook 환경에서는 Image를 불러오게 되는 순간 Rviz가 멈추는 이상한 Error가 발생하여 Map point만 확인하였습니다.  
Bag File을 원본을 사용할때 너무 빨리 실행됭 실질적으로 Rviz에서 Update시킬 수 없는 Error가 발생할 시 -r option을 활용하여 재생속도를 늦출 수 있습니다.  

<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/17.png" height="250" width="600" /></div><br>
<br>


#### RGBD SLAM
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/18.png" height="250" width="600" /></div><br>
(1) rtabmap-ros 설치 <code>sudo apt-get install ros-melodic-rtabmap-ros</code>  
(2) Rtabmap node 실행 <code>roslaunch rtabmap_ros demo_robot_mapping.launch</code>  
(3) Bag파일 재생 <code>rosbag play demo_mapping.bag --clock</code>  

<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/19.png" height="250" width="600" /></div><br>
<br>

#### LIDAR SLAM
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/21.png" height="250" width="600" /></div><br>
(1) ceres solver 설치 <code>sudo apt-get install libceres-dev</code>  
(2) catkin _ ws의 src폴더에 aloam 소스 클론 <code>git clone https://github.com/HKUST-Aerial-Robotics/A-LOAM</code>  
(3) catkin _ ws 폴더에서 <code>catkin_make</code> 수행하여 빌드  
(4) aloam 실행 <code>roslaunch aloam_velodyne aloam_velodyne_VLP_16.launch</code>  
(5) 다운받은 bag파일을 play <code>rosbag play nsh_indoor_outdoor.bag --clock</code>  

<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/others/22.png" height="250" width="600" /></div><br>
<br>

### Mission(LOAM과 SL1을 이용해 환경맵핑 해보기)
(1) Launch파일에 다음의 문구 삽입  
```code
<remap from=“velodyne_points” to=“soslab_sl1/pointcloud”/>
​```<br>

(2) 파라미터 조정을 통해 테스트  
scan_line  
mapping_skip_frame  
minimum_range  
mapping_line_resolution  
mapping_plane_resolution  


<br>
<hr>
코드에 문제가 있거나 궁금한 점이 있으면 wjddyd66@naver.com으로  Mail을 남겨주세요.

```